---
title: "ICTSC9のバックボーン解説 – 監視編"
description: "ICTSC9のバックボーン解説 – 監視編"
tags: [ICTSC9]
pubDate: 2018-04-02T19:45:26
slug: "2018/04/02/ICTSC9のバックボーン解説 – 監視編"
draft: false
renderer: "html"
sticky: false
---

<h1>監視</h1>
<h2>はじめに</h2>
<p>こんにちは、今回運営として主に監視の仕事をしていました源波です。</p>
<p>今回は、前回大会の電源トラブルからの反省を元に監視体制を強化しています。結果的には前回と同じ電源周りのトラブルで大会を一時中断せざるを得ない状況に陥りましたが、監視のおかげで原因の切り分けがスムーズに進み、早期の復旧につながったのではないかと考えています。</p>
<p><img decoding="async" loading="lazy" src="/images/wp/2018/03/Gy9CQgo-1.png.webp" alt="" width="2326" height="924" class="alignnone size-full wp-image-1575" /></p>
<p>今大会では、大まかに上の図のような監視体制を取りました。</p>
<h2>Grafana</h2>
<p>Grafanaでは、PrometheusやZabbixで取得したデータをグラフ化して、値を視覚から感じ取ることができました。Grafanaの監視画面は以下のようになっていました。</p>
<p><img decoding="async" src="https://i.imgur.com/vulqPUY.jpg.webp" alt="" /></p>
<p><img decoding="async" src="https://i.imgur.com/8rBcZCL.png.webp" alt="" /></p>
<p><img decoding="async" src="https://i.imgur.com/YRPMyW4.png.webp" alt="" /></p>
<p>監視項目については、それぞれの節で説明します。</p>
<h2>Prometheus</h2>
<p>前回大会までは監視ツールとしてすべてZabbixを使用していましたが、今大会からは部分的にPrometheusに移行しています。Prometheusでは、Node Exporterを用いて物理サーバーのホストOSやVMのゲストOSのステータス監視を行っていました。具体的には以下の値を取得し、可視化していました。</p>
<ul>
<li>CPU使用率</li>
<li>メモリ使用率</li>
<li>ディスク容量</li>
<li>コンテストサイトのレスポンスタイム</li>
</ul>
<p>前述した電源トラブルの際には、6台のIBM X3750 m4のうち、同系統の電源に接続していた3台のCPU使用率監視が途切れ、電源系統の異常に気づくことができました。<br />
また、ディスク容量の監視によって、コンテストサイトのDBバックアップが正常に取れていないというトラブルに即座に気づくことができました。</p>
<h2>Zabbix</h2>
<p>Zabbixでは、Prometheusに移行することができなかったネットワーク機器と物理サーバーの各種センサ値の監視を行いました。また、先程の図にはありませんでしたが、VMゲストのPing,SSH監視、バックボーンのネットワーク機器、各チームに提供したネットワーク機器のPing,Telnet監視も行っていました。今回のバックボーン構成では、Home NOC Operators Group様より提供頂いたBGPフルルートを、Juniper様よりお借りしたSRX1500で受けていたので、SNMPでその経路数を取得するということも行いました。具体的には以下の値を取得していました。</p>
<ul>
<li>各ネットワーク機器のトラフィック量</li>
<li>各ネットワーク機器のPing,Telenet疎通性</li>
<li>各VMのPing,SSH疎通性</li>
<li>BGPルート数</li>
<li>物理サーバーの消費電力</li>
<li>物理サーバー内の温度</li>
</ul>
<p>競技中は、各ネットワーク機器のトラフィックをスクリーンに移しつつ眺めていました。また、トラフィックの監視を行うことによって、「rs232c使ったことあります？」問題のAlaxalaのL2SWから流れる大量のトラフィックがバックボーン機材まで影響を与えているというトラブルを発見することができました。</p>
<p>２日目の昼間には、上流ISPの障害がありましたが、これもBGPのルート数が一気に5000経路ほどなくなっているのが、グラフから伝わってくるという面白い体験ができました。</p>
<h2>graylog</h2>
<p>graylogでは、ネットワーク機器やDNSサーバーのsyslog収集といったテキスト処理を行いました。これらは、競技中はあまり監視は行わなかったものの、競技終了後に眺めようということで記録をしてあります。</p>
<h2>まとめ</h2>
<p>今回監視サーバー群は、問題VMや他ライフサーバー群と同じく OpenStack上に構築してありました。電源トラブルが拡大した際には、監視サーバー群からの応答もなくなってしまうということもありました。たまたま最初に落ちたサーバーに監視サーバー群が乗っていなかったため早期の原因究明につながりましたが、次回は今回の失敗をもとに監視サーバー群は外部に設置するなどの対策を行いたいと考えています。</p>
